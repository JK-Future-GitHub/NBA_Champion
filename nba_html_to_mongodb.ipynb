{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pngs/nba_html_to_mongodb.png)\n",
    "1. Define Foundation\n",
    "2. Player Data to MongoDB Cloud\n",
    "<br> - 1/2 MVP + Defensive Player of the Year\n",
    "<br> - 2/2 All NBA Team + All Defensive Team\n",
    "3. Team Data to MongoDB Cloud\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ➤ 1 Define Foundation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_URL = r\"https://www.basketball-reference.com/\"\n",
    "ALPHABET_URL = r\"https://www.basketball-reference.com/players/\"\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\knaue\\Documents\\Data\\NBA\"\n",
    "PLAYER_HTML_PATH = os.path.join(DATA_PATH, \"PLAYER_HTML\")\n",
    "AWARD_HTML_PATH = os.path.join(DATA_PATH, \"AWARD_HTML\")\n",
    "SEASON_HTML_PATH = os.path.join(DATA_PATH, \"SEASON_HTML\")\n",
    "\n",
    "PLAYER_PATH = os.path.join(DATA_PATH, \"Player_Urls.csv\")\n",
    "AWARD_PATH = os.path.join(DATA_PATH, \"Award_Urls.csv\")\n",
    "SEASON_PATH = os.path.join(DATA_PATH, \"Season_Urls.csv\")\n",
    "\n",
    "PARSER = 'lxml'\n",
    "ONLY_ACTIVE_PLAYER = None \n",
    "\n",
    "USERNAME = \"\" # YOUR USERNAME\n",
    "PASSWORD = \"\" # YOUR PASSWORD\n",
    "DB_NAME = \"nba\"\n",
    "# PLAYER\n",
    "COLLECTION_PLAYER = \"player\"\n",
    "PLAYER_TABLE_IDS = [\"per_game\", \"playoffs_per_game\", \"advanced\", \"playoffs_advanced\", \"totals\"] # field names in document\n",
    "PLAYER_FIELD_STANDARD_LIST = [\"name\", \"position\", \"height\", \"weight\", \"hall_of_fame\", \"active\"]\n",
    "PLAYER_FIELD_CHAMPION = \"champion\"\n",
    "PLAYER_FIELD_MVP = \"mvp\"\n",
    "PLAYER_FIELD_DPOY = \"dpoy\"\n",
    "PLAYER_FIELD_ALL_NBA = \"all_nba\"\n",
    "PLAYER_FIELD_ALL_DEFENSIVE = \"all_defensive\"\n",
    "# TEAM SEASONS\n",
    "COLLECTION_TEAM = \"team\"\n",
    "TEAM_TABLE_IDS = ['per_game-team', 'per_game-opponent', 'advanced-team']\n",
    "TEAM_FIELD_PLAYOFF = \"playoff\"\n",
    "TEAM_FIELD_CONFERENCE = \"conference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_to_int(cell_value: str):\n",
    "    if cell_value[-2:] == \"00\":\n",
    "        return (int(cell_value[:2]) + 1)*100\n",
    "    else:\n",
    "        return int(cell_value[:2] + cell_value[-2:])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoDBAgent:\n",
    "    name = \"MongoDBAgent\"\n",
    "\n",
    "    def __init__(self, con_string: str, db: str):\n",
    "        self.__client = pymongo.MongoClient(con_string)\n",
    "        self.__db = self.__client[db]\n",
    "        self.__connect_db()\n",
    "\n",
    "\n",
    "    def __connect_db(self):\n",
    "        self.__client.server_info()\n",
    "\n",
    "\n",
    "    def find(self, collection_str: str, query: dict, count=False):\n",
    "        collection = self.__db[collection_str]\n",
    "        documents = collection.find(query)\n",
    "        if count: return collection.count_documents(query)\n",
    "        if collection.count_documents(query) == 0: return None\n",
    "        return documents\n",
    "\n",
    "\n",
    "    def insert_one(self, collection_str: str, data: dict):\n",
    "        collection = self.__db[collection_str]\n",
    "        return_statement = collection.insert_one(data)\n",
    "\n",
    "\n",
    "    def update_one(self, collection_str: str, filter: dict, data):\n",
    "        collection = self.__db[collection_str]\n",
    "        collection.update_one(filter=filter, update=data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ➤ 2 Player Data to MongoDB Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb_agent = MongoDBAgent(con_string=f\"mongodb+srv://{USERNAME}:{PASSWORD}@maincluster.grb4d.mongodb.net/test\", db=DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5023/5023..."
     ]
    }
   ],
   "source": [
    "df_player = pd.read_csv(PLAYER_PATH, encoding=\"utf-8-sig\", index_col=False)\n",
    "\n",
    "if ONLY_ACTIVE_PLAYER != None:\n",
    "    df_player = df_player[df_player['Active'] == ONLY_ACTIVE_PLAYER]\n",
    "\n",
    "i=0\n",
    "for player, pos, ht, wt, h_o_f, active, url, path in df_player[['Player', 'Pos', 'Ht', 'Wt', 'Hall_of_Fame', 'Active', 'Url', 'Path']].values:\n",
    "    i += 1\n",
    "    sys.stdout.write(f\"\\r{i}/{len(df_player)}...\")\n",
    "    \n",
    "    # Normal Stats\n",
    "    for field, value in zip(PLAYER_FIELD_STANDARD_LIST, [player, pos, ht, wt, h_o_f, active]):\n",
    "        mongodb_agent.update_one(collection_str=COLLECTION_PLAYER, filter={\"player_id\": url}, data={ \"$set\": {field: value} })\n",
    "    \n",
    "    with open(path, 'r', encoding=\"utf-8-sig\") as f:\n",
    "        content = BeautifulSoup(f.read(), PARSER)\n",
    "        for table_id in PLAYER_TABLE_IDS: \n",
    "            table = content.find(\"table\", id=table_id)\n",
    "            if table == None: continue\n",
    "            \n",
    "            # Filter Row/Columns\n",
    "            df_table = pd.read_html(str(table))[0]\n",
    "            df_table = df_table[df_table['Season'].notna()]\n",
    "            df_table.drop([col for col in df_table.columns if \"Unnamed:\" in col], axis=\"columns\", inplace=True)\n",
    "            \n",
    "            # Season\n",
    "            df_table = df_table[df_table['Season'].str.contains('-')] \n",
    "            df_table['Season'] = df_table['Season'].apply(lambda x: season_to_int(x))\n",
    "            \n",
    "            # Lg\n",
    "            df_table['Lg'] = df_table['Lg'][df_table['Lg'] == \"NBA\"]\n",
    "            \n",
    "            # Tm\n",
    "            team_ids = []\n",
    "            for tr in table.find(\"tbody\").find_all(\"tr\")[:len(df_table)]:\n",
    "                td = tr.find(\"td\", attrs={\"data-stat\":\"team_id\"})\n",
    "                \n",
    "                if td == None:\n",
    "                    team_ids.append(urljoin(MAIN_URL, \"DidNotPlay\")) \n",
    "                    continue\n",
    "                if td.a == None:\n",
    "                    team_ids.append(urljoin(MAIN_URL, td.text))\n",
    "                    continue\n",
    "                team_ids.append(urljoin(MAIN_URL, td.a['href']))\n",
    "             \n",
    "            df_table.insert(loc=3, column='Tm_id', value=team_ids)\n",
    "            \n",
    "            # Insert/Update\n",
    "            player_count = mongodb_agent.find(collection_str=COLLECTION_PLAYER, query={\"player_id\": url}, count=True) \n",
    "            if player_count == 0:\n",
    "                mongodb_agent.insert_one(collection_str=COLLECTION_PLAYER, data={\"player_id\": url, table_id: df_table.to_dict(\"records\")}) \n",
    "            else: \n",
    "                mongodb_agent.update_one(collection_str=COLLECTION_PLAYER, filter={\"player_id\": url}, data={ \"$set\": {table_id: df_table.to_dict(\"records\")} })\n",
    "\n",
    "            # Champions\n",
    "            if table_id == \"playoffs_per_game\": \n",
    "                for span in table.find(\"tbody\").findAll(\"span\", class_=\"sr_ring\"):\n",
    "                    mongodb_agent.update_one(collection_str=COLLECTION_PLAYER, filter={\"player_id\": url}, data={ \"$addToSet\": {PLAYER_FIELD_CHAMPION: {\"Season\": season_to_int(span.previous)} } })    \n",
    "            \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ➤ 2 Player Data to MongoDB Cloud\n",
    "#### 1/2 MVP + Defensive Player of the Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67..."
     ]
    }
   ],
   "source": [
    "df_award = pd.read_csv(AWARD_PATH, encoding=\"utf-8-sig\")\n",
    "\n",
    "i=0\n",
    "for season, path in df_award[['Season', 'Voting_Path']].values[:-2]:\n",
    "    i += 1\n",
    "    sys.stdout.write(f\"\\r{i}/{len(df_award) - 2}...\")\n",
    "    \n",
    "    with open(path, 'r', encoding=\"utf-8-sig\") as f:\n",
    "        content = BeautifulSoup(f.read(), PARSER)\n",
    "        \n",
    "        for table_id in [\"mvp\", \"dpoy\"]:\n",
    "            table = content.find(\"table\", id=table_id)\n",
    "            \n",
    "            if table == None and table_id == \"mvp\": \n",
    "                table = content.find(\"table\", id=f\"nba_{table_id}\")\n",
    "            if table == None: \n",
    "                continue\n",
    "            \n",
    "            df_table = pd.read_html(str(table))[0]\n",
    "            df_table = df_table.droplevel(0, axis=1)\n",
    "            df_table = df_table[['Rank', 'Player', 'Share']]\n",
    "            if df_table['Rank'].dtype != np.int64:\n",
    "                df_table['Rank'] = df_table['Rank'].apply(lambda cell: int(cell.replace(\"T\", \"\")))\n",
    "            \n",
    "            player_urls = []\n",
    "            for td in table.find(\"tbody\").find_all(\"td\", attrs={\"data-stat\":\"player\"}):\n",
    "                player_urls.append(urljoin(MAIN_URL, td.a['href']))\n",
    "                \n",
    "            df_table['Player_Urls'] = player_urls\n",
    "            for rk, share, url in df_table[['Rank', 'Share', 'Player_Urls']].values:\n",
    "                if table_id == \"mvp\":\n",
    "                    mongodb_agent.update_one(collection_str=COLLECTION_PLAYER, filter={\"player_id\": url}, data={ \"$addToSet\": {PLAYER_FIELD_MVP: {\"Season\": int(season), \"Rank\": rk, \"Share\": share}} })\n",
    "                else:\n",
    "                    mongodb_agent.update_one(collection_str=COLLECTION_PLAYER, filter={\"player_id\": url}, data={ \"$addToSet\": {PLAYER_FIELD_DPOY: {\"Season\": int(season), \"Rank\": rk, \"Share\": share}} })\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ➤ 2 Player Data to MongoDB Cloud\n",
    "#### 2/2 All NBA Team + All Defensive Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All_NBA\n",
      "180/180...\n",
      "All_DEFENSIVE\n",
      "108/108..."
     ]
    }
   ],
   "source": [
    "df_award = pd.read_csv(AWARD_PATH, encoding=\"utf-8-sig\")\n",
    "for field, path in df_award[['Season', 'Voting_Path']].values[-2:]:\n",
    "    with open(path, 'r', encoding=\"utf-8-sig\") as f:\n",
    "        content = BeautifulSoup(f.read(), PARSER)\n",
    "        if field == \"All_NBA\":\n",
    "            print(field)\n",
    "            table = content.find(\"table\", id=\"awards_all_league\")\n",
    "        elif field == \"All_DEFENSIVE\":\n",
    "            print(f\"\\n{field}\")\n",
    "            table = content.find(\"table\", id=\"awards_all_defense\") \n",
    "            \n",
    "        df_table = pd.read_html(str(table))[0]\n",
    "        \n",
    "        df_table = df_table[(df_table['Season'].notna()) & (df_table['Lg'] == \"NBA\") & ((df_table['Tm'] == \"1st\") | (df_table['Tm'] == \"2nd\") | (df_table['Tm'] == \"3rd\"))]\n",
    "        df_table.drop([col for col in df_table.columns if col in ['Lg', 'Tm', 'Voting']], axis=\"columns\", inplace=True)\n",
    "        df_table['Season'] = df_table['Season'].apply(lambda x: season_to_int(x))\n",
    "        \n",
    "        list_tr = table.find(\"tbody\").findAll(\"tr\")\n",
    "        list_tr = [tr for idx, tr in enumerate(list_tr) if idx in list(df_table.index)]\n",
    "        \n",
    "        j=0\n",
    "        for tr, season in zip(list_tr, df_table['Season'].values):\n",
    "                j += 1\n",
    "                sys.stdout.write(f\"\\r{j}/{len(df_table)}...\")\n",
    "                \n",
    "                start = 1\n",
    "                end = start + 5\n",
    "                while tr.find(\"td\", class_=\"left\", attrs={\"data-stat\":str(start)}) == None: \n",
    "                    start = end\n",
    "                    end = start + 5\n",
    "                \n",
    "                for i in range(start,end,1): \n",
    "                        td = tr.find(\"td\", class_=\"left\", attrs={\"data-stat\":str(i)})\n",
    "                        if td == None: \n",
    "                            print(\"break\")\n",
    "                            break\n",
    "                        url = urljoin(MAIN_URL, td.a['href'])\n",
    "                        if field == \"All_NBA\":\n",
    "                            mongodb_agent.update_one(collection_str=COLLECTION_PLAYER, filter={\"player_id\": url}, data={ \"$addToSet\": {PLAYER_FIELD_ALL_NBA: {\"Season\": int(season)} } })\n",
    "                        if field == \"All_DEFENSIVE\":  \n",
    "                            mongodb_agent.update_one(collection_str=COLLECTION_PLAYER, filter={\"player_id\": url}, data={ \"$addToSet\": {PLAYER_FIELD_ALL_DEFENSIVE: {\"Season\": int(season)} } })                \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ➤ 3 Team Data to MongoDB Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_summary(season: int, lg: str, url: str):\n",
    "    html_path = os.path.join(SEASON_HTML_PATH, url.replace(\"/\", \"{\").replace(\":\", \"}\"))\n",
    "    with open(html_path, 'r', encoding=\"utf-8-sig\") as f:\n",
    "        content = BeautifulSoup(f.read(), PARSER)\n",
    "        \n",
    "        # Conference \n",
    "        for conference, table_id in [(\"East\", \"divs_standings_E\"), (\"West\", \"divs_standings_W\")]:\n",
    "            table = content.find(\"table\", id=table_id)\n",
    "            \n",
    "            # Before 1970\n",
    "            if table == None: \n",
    "                curr_conference = conference \n",
    "                table = content.find(\"table\", id=\"divs_standings_\") \n",
    "                \n",
    "                for tr in table.find(\"tbody\").findAll(\"tr\"):\n",
    "                    if tr['class'][0] == \"thead\" and \"East\" in tr.text: curr_conference = \"East\"\n",
    "                    elif tr['class'][0] == \"thead\" and \"West\" in tr.text: curr_conference = \"West\" \n",
    "                    \n",
    "                    if tr['class'][0] == \"full_table\":\n",
    "                        mongodb_agent.update_one(collection_str=COLLECTION_TEAM, filter={\"team_id\": urljoin(MAIN_URL, tr.a['href'])}, data={ \"$set\": {TEAM_FIELD_CONFERENCE: curr_conference} })  \n",
    "                break\n",
    "            \n",
    "            # Until 1971\n",
    "            for th in table.find(\"tbody\").findAll(\"th\", class_=\"left\", attrs={\"scope\":\"row\", \"data-stat\": \"team_name\"}):\n",
    "                mongodb_agent.update_one(collection_str=COLLECTION_TEAM, filter={\"team_id\": urljoin(MAIN_URL, th.a['href'])}, data={ \"$set\": {TEAM_FIELD_CONFERENCE: conference} })\n",
    "        \n",
    "        \n",
    "        for table_id in TEAM_TABLE_IDS: \n",
    "            table = content.find(\"table\", id=table_id)\n",
    "            df_team = pd.read_html(str(table))[0]\n",
    "\n",
    "            # Change advanced-team columns\n",
    "            if table_id == 'advanced-team': \n",
    "                df_team.columns = [col[1] if 'Unnamed:' in col[0] else '|'.join([str(level_col) for level_col in col]) for col in df_team.columns]\n",
    "            \n",
    "            # Filter Row/Columns\n",
    "            df_team.drop([col for col in df_team.columns if \"Unnamed:\" in col], axis=\"columns\", inplace=True)\n",
    "            del df_team['Rk']\n",
    "            del df_team['Team']\n",
    "            df_team = df_team[:-1]\n",
    "            \n",
    "            # Change per_game-opponent columns\n",
    "            if table_id == 'per_game-opponent': \n",
    "                df_team.columns = [f\"{col}_opp\" for col in df_team.columns]\n",
    "                \n",
    "            # Get team url -> team id    \n",
    "            teams_url = []\n",
    "            for td in table.find(\"tbody\").findAll(\"td\", class_=\"left\", attrs={\"data-stat\":\"team\"}):\n",
    "                teams_url.append(urljoin(MAIN_URL, td.a['href']))\n",
    "                \n",
    "            if len(teams_url) != len(df_team):\n",
    "                ValueError()\n",
    "            \n",
    "            # Insert/Update\n",
    "            for team_url in teams_url:\n",
    "                team_count = mongodb_agent.find(collection_str=COLLECTION_TEAM, query={\"team_id\": team_url}, count=True) \n",
    "                if team_count == 0:\n",
    "                    mongodb_agent.insert_one(collection_str=COLLECTION_TEAM, data={\"team_id\": team_url, \"season\": int(season), \"lg\": lg}) \n",
    "                \n",
    "            for team_url, team_dict in zip(teams_url, df_team.to_dict(\"records\")):\n",
    "                mongodb_agent.update_one(collection_str=COLLECTION_TEAM, filter={\"team_id\": team_url}, data={ \"$set\": {table_id: team_dict} })\n",
    "\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_standing(champ: str, url: str):\n",
    "    html_path = os.path.join(SEASON_HTML_PATH, url.replace(\"/\", \"{\").replace(\":\", \"}\"))\n",
    "    table_id = \"expanded_standings\"\n",
    "    with open(html_path, 'r', encoding=\"utf-8-sig\") as f:\n",
    "        content = BeautifulSoup(f.read(), PARSER)\n",
    "        table = content.find(\"table\", id=table_id)\n",
    "        df_team = pd.read_html(str(table))[0]\n",
    "        \n",
    "        # Filter Row/Columns\n",
    "        df_team = df_team.droplevel(0, axis=1)\n",
    "        df_team.drop([col for col in df_team.columns if col not in ['Rk', 'Team', 'Overall', 'Home', 'Road', 'Pre', 'Post', '≤3', '≥10', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar', 'Apr']],\n",
    "                     axis=\"columns\",\n",
    "                     inplace=True)\n",
    "        \n",
    "        # Season\n",
    "        df_team.rename(columns={'Rk':'Rk_Season'}, inplace=True)\n",
    "        \n",
    "        # Champion\n",
    "        champ_list = df_team['Team'].str.contains(champ).to_list()\n",
    "        \n",
    "        # Team\n",
    "        team_list = df_team.pop(item=\"Team\")\n",
    "        \n",
    "        # Get team url -> team id\n",
    "        teams_url = []\n",
    "        for td in table.find(\"tbody\").findAll(\"td\", class_=\"left\", attrs={\"data-stat\":\"team_name\"}):\n",
    "            teams_url.append(urljoin(MAIN_URL, td.a['href']))\n",
    "            \n",
    "        if len(teams_url) != len(df_team) != len(champ_list) != len(team_list):\n",
    "            ValueError()\n",
    "        \n",
    "        # Insert/Update\n",
    "        for team_url, team_dict, champ_bool, team_name in zip(teams_url, df_team.to_dict(\"records\"), champ_list, team_list):\n",
    "            mongodb_agent.update_one(collection_str=COLLECTION_TEAM, filter={\"team_id\": team_url}, data={ \"$set\": {\"name\": team_name}})\n",
    "            mongodb_agent.update_one(collection_str=COLLECTION_TEAM, filter={\"team_id\": team_url}, data={ \"$set\": {\"champion\": champ_bool}})\n",
    "            mongodb_agent.update_one(collection_str=COLLECTION_TEAM, filter={\"team_id\": team_url}, data={ \"$set\": {table_id: team_dict} })\n",
    "        \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def champion_in_percent(cell: float):\n",
    "    if cell == 0: return 0 \n",
    "    if cell == 1: return 100\n",
    "    if cell == 2: return 50\n",
    "    if cell == 3 or cell == 4: return 25\n",
    "    if cell >= 5 and cell <= 8: return 12.5\n",
    "    if cell >= 9 and cell <= 16: return 6.25\n",
    "    if cell >= 17 and cell <= 32: return 3.125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_win(cell: str)-> int:\n",
    "    if pd.isna(cell):\n",
    "        return 0\n",
    "    return int(cell.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playoff_standing(url: str):\n",
    "    html_path = os.path.join(SEASON_HTML_PATH, url.replace(\"/\", \"{\").replace(\":\", \"}\"))\n",
    "    table_id = \"expanded_standings\"\n",
    "    with open(html_path, 'r', encoding=\"utf-8-sig\") as f:\n",
    "        content = BeautifulSoup(f.read(), PARSER)\n",
    "        table = content.find(\"table\", id=table_id)\n",
    "        df_team = pd.read_html(str(table))[0]\n",
    "\n",
    "        # Filter Row/Columns\n",
    "        df_team = df_team.droplevel(0, axis=1)\n",
    "        df_team.drop([col for col in df_team.columns if col not in ['Rk', 'Overall']],\n",
    "                     axis=\"columns\", \n",
    "                     inplace=True)\n",
    "        \n",
    "        # Champion Percent\n",
    "        df_team['Champion_Percent'] = df_team['Rk'].apply(lambda cell: champion_in_percent(cell=cell))\n",
    "        \n",
    "        # Champion Win share\n",
    "        df_team['Overall'] = df_team['Overall'].apply(lambda cell: get_win(cell))\n",
    "        max_wins = df_team['Overall'].values[0]\n",
    "        df_team['Overall'] = df_team['Overall'].apply(lambda cell: cell/max_wins)\n",
    "        df_team.rename(columns={'Overall':'Champion_Win_Share'}, inplace=True)\n",
    "        \n",
    "        # Get team url -> team id\n",
    "        teams_url = []\n",
    "        for td in table.find(\"tbody\").findAll(\"td\", class_=\"left\", attrs={\"data-stat\":\"team_name\"}):\n",
    "            teams_url.append(urljoin(MAIN_URL, td.a['href']))\n",
    "            \n",
    "        if len(teams_url) != len(df_team):\n",
    "            ValueError()\n",
    "        \n",
    "        # Insert/Update\n",
    "        for team_url, team_dict in zip(teams_url, df_team.to_dict(\"records\")):\n",
    "            mongodb_agent.update_one(collection_str=COLLECTION_TEAM, filter={\"team_id\": team_url}, data={ \"$set\": {TEAM_FIELD_PLAYOFF: team_dict} })\n",
    "        \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season Summary\n",
      "73/73...\n",
      "Season Standings\n",
      "73/73...\n",
      "Playoff Standings\n",
      "73/73..."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(SEASON_PATH, encoding=\"utf-8-sig\")\n",
    "\n",
    "# SEASON SUMMARY\n",
    "print(\"Season Summary\")\n",
    "i = 0\n",
    "for url in df['Url_Season_Summary'].unique(): \n",
    "    i += 1\n",
    "    sys.stdout.write(f\"\\r{i}/{len(df['Url_Season_Summary'].unique())}...\")\n",
    "    season = df.loc[df['Url_Season_Summary'] == url, \"Season\"].values[0]\n",
    "    lg = df.loc[df['Url_Season_Summary'] == url, \"Lg\"].values[0]\n",
    "    get_season_summary(season=season, lg=lg, url=url)\n",
    "    \n",
    "\n",
    "# SEASON STANDINGS  \n",
    "print(\"\\nSeason Standings\")\n",
    "i = 0     \n",
    "for url in df['Url_Season_Standings'].unique():\n",
    "    i += 1\n",
    "    sys.stdout.write(f\"\\r{i}/{len(df['Url_Season_Standings'].unique())}...\")\n",
    "    champ = df.loc[df['Url_Season_Standings'] == url, \"Champion\"].values[0]\n",
    "    get_season_standing(champ=champ, url=url)\n",
    "    \n",
    "\n",
    "# PLAYOFF STANDINGS    \n",
    "print(\"\\nPlayoff Standings\")\n",
    "i = 0     \n",
    "for url in df['Url_Playoff_Standings'].unique():\n",
    "    i += 1\n",
    "    sys.stdout.write(f\"\\r{i}/{len(df['Url_Playoff_Standings'].unique())}...\")\n",
    "    get_playoff_standing(url=url)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa6708a3e9a8fadf3ed03c473ecc2d2a3bf5cea3ad7526930f095379c19fd7a0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
